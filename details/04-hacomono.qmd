---
title: "株式会社hacomono"
date: last-modified
categories:
  - "正社員"
description: |
  データエンジニアとして以下に従事<br>
  - 自社環境・顧客環境の DWH 構築・運用<br>
  - 自社データ基盤の運用改善・機能追加
Period: "2024/04 - 2024/10"
---

:会社概要・雇用形態 (2024年時点) {#tbl-company tbl-colwidths="[20,80]"}

|              |                                                                                                     |
| :---         | :---                                                                                                |
| 事業内容     | 月額型店舗のための会員管理・予約・キャッシュレス決済システム「hacomono」開発・販売                  |
| 資本金       | 100百万円                                                                                           |
| 売上高       | 非公開                                                                                              |
| 従業員数     | 217名                                                                                               |
| 上場／非上場 | 非上場                                                                                              |
| 雇用形態     | 正社員                                                                                              |
| 勤務地       | フルリモート (居住地 北海道札幌市)<br>年に数回東京原宿本社へ出社                                    |
| 所属         | [2024/04 - 2024/08] 基盤本部 データ基盤部<br>[2024/09 - 2024/10] データ本部 データ基盤部 (組織改編) |

<!--
**入社動機**
- しっかりとしたデータ基盤の構築・運用の経験を積んでおきたかった点が一番大きかったです。Terraform と GitHub で管理されており良い経験が得られると考えました。
- dbt によるデータパイプライン導入や DWH サービス選定 (BigQuery から Snowflake へのリプレイス) ができると聞きました。自分はそれらの利用経験があったのでその経験を更に磨き上げられる機会を魅力的に感じました。
- データエンジニアの増員の予定があるので今後2-3年でリーダー経験が積めるようになると言われ、自身のキャリアとしてもプラスになると考えました。
- データ利活用に向けた意識がまだまだ低く、データ基盤側から働きかけてデータ利活用が行える組織作りもやってほしいという期待を持っていただき、それは自分のキャリアの中で是非やりたいことだったので意気に感じました。

**退職動機**
- 会社方針としてデータを顧客環境に転送してサービス料を取るという収益構造が強固なものになりデータの中継地点の役割に終始してしていく必要のある状況になってしまいました。エンジニアとしてもデータ組織に所属する人間としても更に成長を目指して別の場で挑戦したいと考えています。
    - データをプロダクトや事業成長のように社内でより活かすことができる場に身を置きたいと考えています。
- 体制変更により入社当初思い描いていたことがやれなくなってしまったことも大きいです。
    - 入社直後にデータエンジニアが1名退職し、社内のデータエンジニアが私1名だけになってしまいました。その結果、データパイプラインはデータエンジニア不在でも利用ができ、つまりデータエンジニアとして新規性のある経験の得にくい TROCCO を推進されてしまいました。入社時にやりたいとおもっていた dbt 推進によるデータ信頼性向上の取り組みが行えなくなってしまいました。
    - 入社して1ヶ月後にデータ利活用を行える組織作りを推進する部署 (データ戦略部) が出来て、マネージャーも併せて入社しました。自分としてはデータ基盤部が主導してこのようなタスクを進めたかったのですが、データ基盤部は自分1名だけになってしまったこともありパワーバランスで負けてしまいました。組織作りなど全社横断的なタスクはデータ戦略部が行ない、切り出された純粋なデータ基盤タスクを引き受けるだけの関係になってしまいました。
    - データエンジニア増員計画が入社前と異なり縮小傾向になり、かつシニアエンジニアの採用に絞られてしまい、マネジメント経験を積む見込みがなくなってしまいました。
-->

::: {.callout-note appearance="simple"}

|              |                              |
| :---         | :---                         |
| **[データ]** | データエンジニアとしての業務 |
| **[その他]** | その他業務                   |

:::

## 1. [データ] 顧客環境 BigQuery へのバッチ転送システム開発・運用

### 1.1. 概要

- hacomono アプリDBに蓄積されたデータを顧客環境 BigQuery へ日次バッチ転送するためのシステム開発・運用

### 1.2. 期間

- 2024/04 - 2024/10

### 1.3. 規模・役割

- [2024/04 - 2024/05]
    - 役割：メンバー
    - 規模：2名
- [2024/06 - 2024/10]
    - 役割：リーダー
    - 規模：1名

### 1.4. 担当業務

1. [2024/04 - 2024/05] (2名) 定常運用業務・業務引き継ぎ
1. [2024/06 - 2024/10] (私1名) 定常運用業務・障害対応

### 1.5. 機能開発・実装詳細

- GitHub と Terraform (Terragrunt) を用いて以下の構成を実装します。
    - RDS MySQL or Aurora MySQL をデータソースとして Embulk で顧客環境 BigQuery にデータ転送を行う
- システム構成図は下記ブログをご参照ください。
    - [hacomonoデータ基盤におけるデータ転送の課題と今後の対応 - hacomono TECH BLOG](https://techblog.hacomono.jp/entry/2024/07/02/1100)

### 1.6. 目的・背景

- 顧客に向けて DWH 提供を行うサービスを開始するために暫定的に構築したシステムを運用し続けている状況です。

### 1.7. 課題

- 全量のデータを転送させているためデータ増加により転送時間が延びてしまい、具体的には以下の問題が起こるようになりました。
    - RDS BurstBalance を使い切ることによる転送の不安定化が起こる
    - データソース側の DB で一時領域不足になる
    - 顧客約束の時刻に転送が間に合わなくなる

### 1.8. 工夫した点

- 問題発生源の特定のために Embulk のログやデータソースのメトリクスから真因を究明するよう努めました。

### 1.9. 成果

> - RDS BurstBalance を使い切ることによる転送の不安定化が起こる

ReadIOPS の数値が支配的だったため並列実行数を減らしたり、Embulk の読み込み量のパラメータを調整したりすることで BurstBalance を使い切らないまま可能な限り早く転送させるよう調整を行いました。

### 1.10. 担当フェーズ

- 運用
- 保守

### 1.11. 開発環境

- GitHub
- Terraform
- Embulk
- AWS
    - ECS
    - RDS MySQL
    - Aurora MySQL
    - VPC
- Google Cloud
    - BigQuery

## 2. [データ] 社内 BigQuery 環境構築・運用

### 2.1. 概要

- hacomono プロダクトのデータベースから BigQuery へデータを転送し社内向けに DWH を作成するシステムの運用・保守

### 2.2. 期間

- 2024/04 - 2024/10

### 2.3. 規模・役割

- [2024/04 - 2024/05]
    - 役割：メンバー
    - 規模：2名
- [2024/06 - 2024/10]
    - 役割：リーダー
    - 規模：1名

### 2.4. 担当業務

1. [2024/04 - 2024/05] (2名) 定常運用業務・業務引き継ぎ
1. [2024/06 - 2024/10] (私1名) 定常運用業務・運用改善業務

### 2.5. 機能開発・実装詳細

- (新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能

### 2.6. 目的・背景

- 社内の分析需要に応えるために権限管理の行き届いた新しい BigQuery 環境を構築・運用が必要となりました。

### 2.7. 課題

> - (新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能

概ね IaC 対応が済んでいましたが権限追加に関してはコンソールからの手動追加対応となっておりました。これにより環境差分が生じ `terraform apply` が通らなくなる状況でした。

### 2.8. 工夫した点

> - (新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能

権限を最小限に留めるためにプロジェクトレベルでの権限付与をせず、データセット毎に権限を付与する運用に変更しました。

### 2.9. 成果

> - (新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能

IaC 化により権限の種類とユーザーを CSV ファイルに集約でき、権限付与状況をリポジトリで管理できるようになりました。

### 2.10. 担当フェーズ

- 運用
- 保守

### 2.11. 開発環境

- GitHub
- Terraform
- Embulk
- AWS
    - ECS
    - RDS MySQL
    - Aurora MySQL
    - VPC
- Google Cloud
    - BigQuery

## 3. [データ] 顧客環境 BigQuery へのリアルタイム転送システム開発・運用

### 3.1. 概要

- hacomono に蓄積されたデータを顧客環境 BigQuery へリアルタイム転送するためのシステム開発・運用
- 2024年8月まで開発を続けていましたが、契約締結できず検証段階で開発を中断しています。

### 3.2. 期間

- 2024/04 - 2024/08

### 3.3. 規模・役割

- [2024/04 - 2024/05]
    - 役割：メンバー
    - 規模：2名
- [2024/06 - 2024/08]
    - 役割：リーダー
    - 規模：2名

### 3.4. 担当業務

1. [2024/04 - 2024/05] (2名) 開発引き継ぎ
1. [2024/06 - 2024/08] 主機能開発・進捗管理

### 3.5. 機能開発・実装詳細

- GitHub と Terraform (Terragrunt) を用いて以下の構成を実装します。
    - [主機能] RDS MySQL のデータを Datastream によってリアルタイムに転送させる
        - (新規実装) [周辺機能] ログ出力

### 3.6. 目的・背景

- 顧客要望がありリアルタイム性を重視したテーブルに絞って機能を提供することとなりました。
- 個社向け開発として進めていますが他社への展開も可能な状態に整備する必要があります。

### 3.7. 課題

- 前任者から引き継いだ状態のリポジトリが雑然としており各社向けの設定ファイルを切り替えることができず大規模なリファクタリングが必要でした。
- Datastream の知見のある方が社内にいないため障害発生時の対応のノウハウがない状態でした。

### 3.8. 成果

> - Datastream の知見のある方が社内にいないため障害発生時の対応のノウハウがない状態でした。

RDS 再起動による接続断から復旧する必要がありストリームの復元を行うことがありましたが、この経験により障害発生時に欠損し得るデータに関して説明ができるようになりました。

本機能のオプションサービス化にあたり懸念事項の解像度を上げ、サービスのマニュアル更新の準備に役立てることができました。

### 3.9. 担当フェーズ

- 詳細設計
- 開発
- テスト
- 運用
- 保守

### 3.10. 開発環境

- GitHub
- Terraform
- Terragrunt
- AWS
    - RDS MySQL
    - VPC
- Google Cloud
    - BigQuery
    - Datastream

## 4. [その他] 開発業務以外の活動

### 4.1. 記事執筆

| 日付       | 概要                        | リンク                                                                                                                                  |
| :---       | :---                        | :---                                                                                                                                    |
| 2024/10/08 | Findy Tools 様 特集記事掲載 | [39社のデータ基盤アーキテクチャ特集 - ツールの技術選定のポイントと活用術 - Findy Tools](https://findy-tools.io/articles/data-review/28) |
| 2024/08/21 | Findy Tools 様 レビュー執筆 | [株式会社hacomonoのBigQuery導入事例 - Findy Tools](https://findy-tools.io/products/bigquery/49/231)                                     |
| 2024/07/02 | hacomono テックブログ執筆   | [hacomonoデータ基盤におけるデータ転送の課題と今後の対応 - hacomono TECH BLOG](https://techblog.hacomono.jp/entry/2024/07/02/1100)       |

<!-- - [2024/10/29] <https://techblog.hacomono.jp/entry/2024/10/29/1100> -->
