[
  {
    "objectID": "detail/03-cnsh.html",
    "href": "detail/03-cnsh.html",
    "title": "職務経歴 株式会社シイエヌエス北海道",
    "section": "",
    "text": "事業内容\n\nアプリケーション開発・インフラ構築事業、クラウド構築事業、データ分析・AI事業、DX支援事業\n\n資本金\n\n2500万円\n\n売上高\n\n7億5,351万円\n\n従業員数\n\n39名\n\n上場／非上場\n\n非上場\n\n雇用形態\n\n正社員\n\n勤務地\n\n北海道札幌市"
  },
  {
    "objectID": "detail/03-cnsh.html#会社概要雇用形態-2024年時点",
    "href": "detail/03-cnsh.html#会社概要雇用形態-2024年時点",
    "title": "職務経歴 株式会社シイエヌエス北海道",
    "section": "",
    "text": "事業内容\n\nアプリケーション開発・インフラ構築事業、クラウド構築事業、データ分析・AI事業、DX支援事業\n\n資本金\n\n2500万円\n\n売上高\n\n7億5,351万円\n\n従業員数\n\n39名\n\n上場／非上場\n\n非上場\n\n雇用形態\n\n正社員\n\n勤務地\n\n北海道札幌市"
  },
  {
    "objectID": "detail/03-cnsh.html#プロジェクト一覧",
    "href": "detail/03-cnsh.html#プロジェクト一覧",
    "title": "職務経歴 株式会社シイエヌエス北海道",
    "section": "2. プロジェクト一覧",
    "text": "2. プロジェクト一覧\n新しい順に記載しております。\n\n2.1. プロジェクト以外の社内業務\n\n2.1.1. 新卒採用一次選考の面接官対応\n\n2024年新卒採用：学生6名分\n2025年新卒採用：学生6名分\n\n\n\n2.1.2. データ分析業務担当者育成\n\n育成用プログラム進捗管理 (2023年6月～12月)\n\n利用教材：データサイエンス100本ノック\n育成対象者：7名 (2023年度)\n業務：環境構築手順作成・質疑応答対応・作業進捗管理 (すべて私1名で対応)\n\nローカル上の環境構築手順の共有 (随時)\n\n社内 Wiki にて記事作成\n具体例\n\nAmazon Linux (EC2) + Anaconda + PyStan 環境構築\nWindows + Anaconda + PyStan 環境構築\nUbuntu (WSL2) + Docker (Dockerfile) + CPython + venv 環境構築\nUbuntu (WSL2) + Docker 環境構築 (データサイエンス100本ノック向け)\nAmazon Linux (Cloud9) + pyenv 環境構築\nVSCode と Vim での Linter Formatter 導入方法\n\n\nデータ分析関連技術情報共有 (随時)\n\nニュースサイト・技術ブログ・技術コミュニティにて情報収集し、社内チャットにて随時共有\n\n\n\n\n\n2.2. 情報通信企業向け 機械学習ワークフローと AI プラットフォーム移管\n\n2.2.1. 概要\n\nDataRobot 中心で構築していた機械学習ワークフローから Snowpark ML (Snowflake) 中心の構築への移管\n\n\n\n2.2.2. 期間\n\n[2023年12月-2024年1月] Snowpark ML 事前検証\n[2024年2-3月] 追加調査・ワークフロー設計\n\n\n\n2.2.3. 規模・役割\n\n2023年12-1月体制\n\n役割：メンバー\n規模：1名 (私)\n\n2024年2-3月体制\n\n役割：リーダー\n規模：2名\n\n\n\n\n2.2.4. 担当業務\n\n[2023年12月-2024年1月] (私1名) Snowpark ML の事前検証\n[2024年2-3月] (2名) DataRobot から Snowpark ML への移管のための追加調査\n[2024年3月] (私1名) ワークフロー設計\n\n\n\n2.2.5. 機能開発・実装詳細\n移管前後の構築詳細は以下の通りです。\n\n移管前構築 (AWS MWAA + ECS + DataRobot + Snowflake)\n\nMWAA にてワークフロー管理を行っており DAG ファイルにてジョブを定義し並列処理や直列処理を記述していました。\nMWAA KubernetesPodOperator にて利用する ECS イメージを JupyterHub (ノートブック実行環境) でも共有していたため本番と開発でライブラリ依存関係の齟齬がない環境でした。\nAI プラットフォームとして DataRobot を採用し、ハイパーパラメータチューニングやモデル評価を全てフルマネージドで実施させていました。ただしコストが嵩む問題がありました。\n\n移管後構築 (AWS SageMaker + Snowpark ML + Snowflake)\n\nAI プラットフォームとして Snowpark ML を採用することとしました。使用感は scikit-learn に近く、ラベルエンコーディング・ハイパーパラメータチューニング・モデル評価を自力で実装する必要があります。\nワークフローは “SageMaker + Papermill” でノートブック上での管理となります。\nモデルはモデルレジストリ機能にて管理させます。\n他部署 (他の環境) とも共有できるように素朴な実装を目指しました。\n\n\n\n\n2.2.6. 目的・背景\n\nコスト上の問題から DataRobot の利用を2024年8月に停止するという判断を受けて AI プラットフォームの移行先を探す必要がありました。\n\n\n\n2.2.7. 課題\n\n移行業務は付加価値を生みづらい都合で移行先調査の優先順位が低くなってしまい、分析基盤管理側の社員も移行先調査がほとんど実施できていない状況でした。\nSnowpark ML は新しいサービスのため公式ドキュメント以外で参照出来る情報が社内外ともにかなり限られている状況でした。\n\n\n\n2.2.8. 工夫した点\n\n調査作業での工夫点\n\n後から続く方が参照しやすいように調査記録を丁寧に取りました。\n\nSnowflake 公式のリポジトリに置かれているサンプルコードや公式ドキュメント・公式ライブラリソースコードのどの部分を参照したか記録に残しました。\n調査記録を客先社内公開済み。\n\n必要最低限の領域までの調査に留めることで、スケジュールや実装方針について予定より早く合意を取ることができました。\n\n関係者が多くなるため情報提供をいち早く行うことを優先しました。\n\n\n\n\n\n2.2.9. 成果\n\nSnowpark ML の利用は前例が少なかったため Snowflake 社からの個別開示情報などを利用して情報収集と事前検証を行ないました。結果、既存ワークフローに比べてコスト・性能面・セキュリティ面で優位性があることを示し、客先での先行事例を作ることができました。\n\n価値を生みづらいと見込まれていた移管作業の意義を示したため、注目度を上げ、周囲を巻き込むことに成功しました。客先での政治的にも話を通しやすくすることができました。\n\n本プロジェクトではリーダーとして技術調査・スケジュール策定・チームへの作業指示・顧客他部署への情報共有など多様な役割を担うことができました。\n\n\n\n2.2.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n2.2.11. 開発環境\n\nAWS\n\nSageMaker\nCodeCommit\nSecrets Manager\n\nSQL\n\nSnowflake\n\nPython 実行環境\n\nSageMaker (conda_python3)\n\nAI プラットフォーム\n\nSnowpark ML\n\n\n\n\n\n2.3. 情報通信企業向け データマート整備\n\n2.3.1. 概要\n顧客情報と紐付けて分析や機械学習に利用するための下記特徴量の作成\n\nポイントサービス加盟店と顧客推定住所との距離\nポイントサービス詳細情報\n決済情報\n様々な特徴量を次元圧縮して生成する特徴量\n行動履歴からルールベースで推定されたライブイベント実績\n\n\n\n2.3.2. 期間\n\n[2023年4月-5月] ポイントサービス加盟店と顧客推定住所との距離\n[2023年6月-7月] 決済情報\n[2023年8月-9月] 行動履歴からルールベースで推定されたライフイベント実績\n[2023年10月-12月] 様々な特徴量を次元圧縮して生成する特徴量\n[2024年1月-3月] ポイントサービス詳細情報\n\n\n\n2.3.3. 規模・役割\n\n役割：サブリーダー\n規模：4名\n\n\n\n2.3.4. 担当業務\n\n(主に私1名) データ作成月次作業向けワークフロー構築\n(4名) データレイク調査\n(4名) データ抽出クエリ作成\n(リーダーと私の2名) レビュー\n(4名) 検証\n(4名) 保守\n(4名) 月次運用作業\n\n\n\n2.3.5. 機能開発・実装詳細\nデータマート構成のためのクエリは Juupyter Notebook 上から Python API 経由で実行していましたが、2023年秋頃から dbt Core を導入し SQL ファイルベースへ置き替えつつある状況でした。\n\n[旧環境] Snowflake の Python API 利用 (Jupyter Notebook にて管理)\n\nSnowflake Python API を Jupyter Notebook から実行します。\n\nファイル数が増えたりコード量が増えるとコードの見通しが悪くなりやすい欠点があります。\n\nワークフローは MWAA にて構築しています。\n\n[新環境] dbt Core 利用 (SQL ファイルベース)\n\ndbt Core により SQL ファイル主体で管理を行います。\n\n入出力の依存関係が明示され管理が容易になります。\nCI/CD、自動テスト、自動ドキュメント生成など現代的な開発・運用が可能となります。\n必要に応じて増分データのみを対象とするクエリに変更できます。\n\n\n\n\n\n2.3.6. 目的・背景\n\nデータレイクは充実しているものの、機械学習や顧客情報分析に利用できるデータマートは発展途上のため適宜追加していく必要がありました。\n\n\n\n2.3.7. 課題\n\n分析に利用できる特徴量が不足している状況でした。\n従来作成していた特徴量が上流データの仕様変更や不具合によって作ることができない場合がありました。\nJupyter Notebook で管理しているデータマート向けプログラムが長大なため不具合発生時の原因究明に時間が掛かることが多くありました。\n上流データが全て揃ったタイミングでデータマートの月次更新を行っておりましたが、一部情報をできるだけ早く更新してほしいと言われるようになりました。\n\n\n\n2.3.8. 工夫した点\n\n\n分析に利用できる特徴量が不足している状況でした。\n従来作成していた特徴量が上流データの仕様変更や不具合によって作ることができない場合がありました。\n\n\n\nユーザーアンケートにより整備すべきデータを決定し、より必要とされるデータマートを目指しました。\nできるだけ早くデータを提供できるような上流データを選定しつつ、上流データの障害発生率を調査し取捨選択を行いました。信頼性の高いデータマート運用のために設計時に十分考慮を行いました。\n\n\n\nJupyter Notebook で管理しているデータマート向けプログラムが長大なため不具合発生時の原因究明に時間が掛かることが多くありました。\n上流データが全て揃ったタイミングでデータマートの月次更新を行っておりましたが、一部情報をできるだけ早く更新してほしいと言われるようになりました。\n\n\n\nいずれも解消できるポテンシャルをもつ dbt に移行することとしました。\n\n\n\n2.3.9. 成果\n\nユーザー目線での改善を続けたことでデータマートのアクセス数増加につながり、部内の大きな成果として表彰を受けました。\n自チーム・他チームともに顧客行動予測を行っており、そのために必要な特徴量を自力で作成し社内の多様なモデルの精度向上に貢献できました。\ndbt 移行を推進することでソースコードを SELECT 文中心の理解しやすいものに置き換えることができました。\n上流データが追加されたタイミングで必要に応じてデータ作成処理を行える (セマンティックレイヤ対応ができる) ように dbt 環境に移行を順次進めることができています。\n\nセマンティックレイヤ対応は dbt Core では非対応のため dbt Cloud 導入時の対応となります。\n\n\n\n\n2.3.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n運用\n保守\n\n\n\n2.3.11. 開発環境\n\nAWS\n\nCodeCommit\nCloud9\nSecrets Manager\nSageMaker\nMWAA\nEKS\nECS\n\nSQL\n\nSnowflake\ndbt\n\nPython 実行環境\n\nSageMaker (conda_python3)\nJupyterHub (conda_python3)\n\n\n\n\n\n2.4. 情報通信企業向け 機械学習ワークフローのクラウドシフト\n\n2.4.1. 概要\n\nオンプレ基盤で実施していた顧客行動予測モデル作成 (50モデル分) ワークフローのクラウドシフト\n\n\n\n2.4.2. 期間\n\n[2022年7月-10月] 28モデル分\n[2022年11月-2023年3月] 22モデル分\n\n\n\n2.4.3. 規模・役割\n\n規模：4名\n役割：メンバー\n\n\n\n2.4.4. 担当業務\n\n(私1名) ワークフロー設計・実装\n(私1名) 各ジョブ設計\n(4名) 各ジョブ実装\n(4名) 上流データ調査\n(4名) 機械学習用データ作成クエリの再構成\n(4名) 検証\n(4名) 保守\n\n\n\n2.4.5. 機能開発・実装詳細\nMWAA (Airflow) + EKS + Kubernetes + Papermill な Python 実行環境が構築済みのため以下の要領で実装を行いました。\n\nMWAA ワークフローを設計し DAG ファイルとして実装\n\n大まかにはモデル共通処理を実行した後、モデル固有の処理を並列で実行する流れです。\n\nSnowflake Python API と DataRobot API を実行する Python コード (Jupyter Notebook) を各ジョブの設計内容に応じて作成\n\n機械学習用データ作成・モデリング・スコアリング・モデル評価指標取得などの処理を実装します。\n\n\n\n\n2.4.6. 目的・背景\n\n従来の基盤の廃止に伴い AWS 基盤にて機械学習ワークフローを構築する必要がありました。\n\n\n\n2.4.7. 課題\n\n上流データは仕様が変わりつつ移行済みだったため、従来基盤で利用していたクエリと同等のものを作るには調査・検証の時間を大きく取る必要がありました。\nMWAA と DataRobot に関するノウハウがチーム内になく、自力で調査をしつつ基盤担当者から情報提供を受けながら取り組む必要がありました。\n\n\n\n2.4.8. 工夫した点\n\nMWAA (Airflow) + EKS + Kubernetes + Papermill の構成で並列処理に強いことを利用し、並列処理を最大限活用できるようにジョブの粒度を調整しました。\n移行対象のクエリの量が膨大かつ移行先上流データがどれか分からない状況だったため、初期調査段階では件数比較を活用しある程度当たりを付ける方法で効率的に設計を進めました。\n\n最終的にはレコードの一致率確認を行っていますが、初めから一致率確認をしていると時間が足りなかったと思われます。\n\nMWAA による機械学習ワークフロー構築時に従来手動で実施していた検証処理も含め、最終的に Slack 通知確認で完了するように作業を簡素化することで単純な移行ではなく価値を生むことを意識しました。\n\n\n\n2.4.9. 成果\n\n従来と同等のワークフローを維持しつつ、自動化と時短の工夫を入れることで大幅に運用工数を減らすことができました。\n\n\n\n2.4.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n保守\n運用\n\n\n\n2.4.11. 開発環境\n\nAWS\n\nSageMaker\nCodeCommit\nSecrets Manager\nMWAA\nEKS\nECS\n\nSQL\n\nSnowflake\n\nPython 実行環境\n\nSageMaker (conda_python3)\nJupyterHub (conda_python3)\n\nAI プラットフォーム\n\nDataRobot\n\n\n\n\n\n2.5. 小売企業向け 客数予測処理実行環境構築\n\n2.5.1. 概要\n\nオンプレ基盤で実施していた客数予測処理の AWS 環境移行\n\n\n\n2.5.2. 機能開発・実装詳細\n\nEC2 に Anaconda をインストールしベイズ統計モデル作成環境を構築します。\n顧客の要求により客数予測に費せる日数が4日程度のためその範囲内で十分終了するよう処理の並列化を行います。\n\n\n\n2.5.3. 目的・背景\n\n(前提) PoC として1店舗毎にベイズ統計モデルで客数予測を行うプログラムが作成されており、客数予測処理は1店舗あたり4時間程度かかる状況でした。\n\nその上で4日程度で約200店舗分の客数予測を出す環境構築を求められていました。\nインスタンス性能を上げるための AWS 移行となります。\n\n\n\n\n2.5.4. 課題\n\n要求を満たすためには EC2 高性能インスタンスを利用する必要がありコストは最小限とする必要がありました。\n前任者の作成した並列処理に問題があり総実行時間が長くなってしまいまう。\n経験の浅い作業者に運用を直ちに引き継ぐことになっていたため、手動実行するプロセスを挟むと不具合や遅延が想定されました。\n\n\n\n2.5.5. 工夫した点\n\n前任者の作成していた並列処理は先にコア数に基づきジョブを分割する形式のシェルスクリプトで構成していましたが、各店舗毎にデータ量が異なるため予測処理が早めに終了して遊びの出るコアが発生してしまっていました。\n\n改善のため xargs に並列処理を管理させることで空きコアに逐次ジョブを実行させる構成に改善させ総実行時間を短縮させることができました。\n\n\n\n\n2.5.6. 成果\n\n当初の構成に比べて総実行時間を短縮することができ EC2 インスタンス利用時間の削減に成功しました。\n総実行時間は2日程度に抑えることができ、顧客要求を満たすことができました。\n利用可能なリソースが EC2 のみという制約の中、スクリプトを活用し極力自動化し引継ぎ後の業務負荷を軽減させました。\n\n\n\n2.5.7. 期間\n\n2022年5月-6月\n\n\n\n2.5.8. 担当業務\n\n予測処理実行環境構築 (EC2, Python)\n環境変更に伴う Python コード修正・スクリプト作成\n予測処理実行手順構築\n\n\n\n2.5.9. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n保守\n\n\n\n2.5.10. 開発環境\n\nAWS\n\nEC2\n\nSQL\n\nPostgreSQL\n\nGit\nPython 実行環境\n\nPython (公式)\nAnaconda\n\nシェルスクリプト\n\n\n\n2.5.11. 規模・役割\n\n1名\nメンバー"
  },
  {
    "objectID": "detail/04-hacomono.html",
    "href": "detail/04-hacomono.html",
    "title": "職務経歴 株式会社hacomono",
    "section": "",
    "text": "事業内容\n\n月額型店舗のための会員管理・予約・キャッシュレス決済システム「hacomono」開発・販売\n\n資本金\n\n100百万円\n\n売上高\n\n非公開\n\n従業員数\n\n217名\n\n上場／非上場\n\n非上場\n\n雇用形態\n\n正社員\n\n勤務地\n\nフルリモート (居住地 北海道札幌市)\n年に数回東京原宿本社へ出社"
  },
  {
    "objectID": "detail/04-hacomono.html#会社概要雇用形態-2024年時点",
    "href": "detail/04-hacomono.html#会社概要雇用形態-2024年時点",
    "title": "職務経歴 株式会社hacomono",
    "section": "",
    "text": "事業内容\n\n月額型店舗のための会員管理・予約・キャッシュレス決済システム「hacomono」開発・販売\n\n資本金\n\n100百万円\n\n売上高\n\n非公開\n\n従業員数\n\n217名\n\n上場／非上場\n\n非上場\n\n雇用形態\n\n正社員\n\n勤務地\n\nフルリモート (居住地 北海道札幌市)\n年に数回東京原宿本社へ出社"
  },
  {
    "objectID": "detail/04-hacomono.html#プロジェクト一覧",
    "href": "detail/04-hacomono.html#プロジェクト一覧",
    "title": "職務経歴 株式会社hacomono",
    "section": "2. プロジェクト一覧",
    "text": "2. プロジェクト一覧\n新しい順に記載しております。\n\n2.1. 自社データ基盤上のデータパイプライン構築\n\n2.1.1. 概要\n\n\n2.1.2. 期間\n2024年4月-現在\n\n\n2.1.3. 規模・役割\n\n2024年4-5月体制\n\n役割：メンバー\n規模：2名\n\n2024年6月以降体制\n\n役割：リーダー\n規模：1名\n\n\n\n\n2.1.4. 担当業務\n\n[2024年4-5月] (2名) 定常運用業務・業務引き継ぎ\n[2024年6月] (私1名) 上記に加えて運用改善業務\n\n\n\n2.1.5. 機能開発・実装詳細\n\n\n2.1.6. 目的・背景\n\n\n2.1.7. 課題\n\n\n2.1.8. 工夫した点\n\n\n2.1.9. 成果\n\n\n2.1.10. 担当フェーズ\n\n\n2.1.11. 開発環境\n\n\n\n2.2. 顧客環境内の DWH 構築・運用 (ストリーム転送)\n\n2.2.1. 概要\n\nバッチ処理\n\n\n\n2.2.2. 期間\n2024年4月-現在\n\n\n2.2.3. 規模・役割\n\n2024年4-5月体制\n\n役割：メンバー\n規模：2名\n\n2024年6月以降体制\n\n役割：リーダー\n規模：1名\n\n\n\n\n2.2.4. 担当業務\n\n[2024年4-5月] (2名) 定常運用業務・業務引き継ぎ\n[2024年6月] (私1名) 上記に加えて運用改善業務\n\n\n\n2.2.5. 機能開発・実装詳細\n\n\n2.2.6. 目的・背景\n\n\n2.2.7. 課題\n\n\n2.2.8. 工夫した点\n\n\n2.2.9. 成果\n\n\n2.2.10. 担当フェーズ\n\n\n2.2.11. 開発環境\n\n\n\n2.3. 顧客環境内の DWH 構築・運用 (バッチ処理)\n\n2.3.1. 概要\n\nバッチ処理\n\n\n\n2.3.2. 期間\n2024年4月-現在\n\n\n2.3.3. 規模・役割\n\n2024年4-5月体制\n\n役割：メンバー\n規模：2名\n\n2024年6月以降体制\n\n役割：リーダー\n規模：1名\n\n\n\n\n2.3.4. 担当業務\n\n[2024年4-5月] (2名) 定常運用業務・業務引き継ぎ\n[2024年6月] (私1名) 上記に加えて運用改善業務\n\n\n\n2.3.5. 機能開発・実装詳細\n\n\n2.3.6. 目的・背景\n\n\n2.3.7. 課題\n\n\n2.3.8. 工夫した点\n\n\n2.3.9. 成果\n\n\n2.3.10. 担当フェーズ\n\n\n2.3.11. 開発環境\n\n\n\n2.4. 社内向け DWH 運用\n\n2.4.1. 概要\n\n自社サービスのシングルテナント・マルチテナント環境 RDB から BigQuery へデータを転送し DWH を作成するシステムの運用・保守\n\n\n\n2.4.2. 期間\n2024年4月-現在\n\n\n2.4.3. 規模・役割\n\n2024年4-5月体制\n\n役割：メンバー\n規模：2名\n\n2024年6月以降体制\n\n役割：リーダー\n規模：1名\n\n\n\n\n2.4.4. 担当業務\n\n[2024年4-5月] (2名) 定常運用業務・業務引き継ぎ\n[2024年6月] (私1名) 上記に加えて運用改善業務\n\n\n\n2.4.5. 機能開発・実装詳細\n\n\n2.4.6. 目的・背景\n\n\n2.4.7. 課題\n\n\n2.4.8. 工夫した点\n\n\n2.4.9. 成果\n\n\n2.4.10. 担当フェーズ\n\n\n2.4.11. 開発環境\n\nTerraform\nEmbulk\nAWS\n\nVPC\nECS\nRDS\nAurora\n\nGoogle Cloud\n\nBigQuery"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "職務経歴書",
    "section": "",
    "text": "北海道大学卒業後、オークマ株式会社で約2年Windowsアプリエンジニアを経験し、新光商事LSIデザインセンター株式会社で組込エンジニアとして約3年勤務しました。その後株式会社シイエヌエス北海道にデータエンジニアとして転職しデータマート整備・機械学習ワークフロー構築・機械学習モデル運用業務に従事し、サブリーダーやリーダーを任されました。2024年4月にデータエンジニアとして株式会社hacomonoへ転職し一人データエンジニアとして従事し現在に至ります。"
  },
  {
    "objectID": "index.html#職務要約",
    "href": "index.html#職務要約",
    "title": "職務経歴書",
    "section": "",
    "text": "北海道大学卒業後、オークマ株式会社で約2年Windowsアプリエンジニアを経験し、新光商事LSIデザインセンター株式会社で組込エンジニアとして約3年勤務しました。その後株式会社シイエヌエス北海道にデータエンジニアとして転職しデータマート整備・機械学習ワークフロー構築・機械学習モデル運用業務に従事し、サブリーダーやリーダーを任されました。2024年4月にデータエンジニアとして株式会社hacomonoへ転職し一人データエンジニアとして従事し現在に至ります。"
  },
  {
    "objectID": "index.html#活かせる経験スキル",
    "href": "index.html#活かせる経験スキル",
    "title": "職務経歴書",
    "section": "2. 活かせる経験・スキル",
    "text": "2. 活かせる経験・スキル\n職歴を通して要件定義・開発・テスト・運用・保守のいずれの工程も経験を積んでおります。データエンジニアとしては Snowflake でのデータマート整備、Airflow や dbt を用いたデータパイプライン構築業務を行ったのち、自身で運用・保守まで行っております。機械学習ワークフロー構築・運用も経験済みです。また、前職シイエヌエス北海道ではプロジェクトのリーダーやサブリーダーを任されており、現職hacomonoでは一人データエンジニアとしてデータ基盤に対する責任を負っています。"
  },
  {
    "objectID": "index.html#職務経歴",
    "href": "index.html#職務経歴",
    "title": "職務経歴書",
    "section": "3. 職務経歴",
    "text": "3. 職務経歴\n新しい順に記載しております。\n\n\n\n在籍期間\n所属\n業務概要\n業務詳細\n\n\n\n\n2024年4月 - 現在\n株式会社hacomono\nデータエンジニアのメンバーとして以下に従事- 自社環境・顧客環境のDWH構築・運用- 自社データ基盤の運用改善・機能追加 (データパイプライン構築)\nLink\n\n\n2022年4月 - 2024年3月\n株式会社シイエヌエス北海道\nデータエンジニアのサブリーダーやリーダーとして以下に従事- データマート整備- 機械学習基盤上でのワークフロー構築\nLink\n\n\n2018年8月 - 2022年3月\n新光商事LSIデザインセンター株式会社\n組込エンジニアのメンバーとして以下に従事- 車載マイコンの機能開発業務- インバータやモータの制御開発業務\nLink\n\n\n2016年4月 - 2018年7月\nオークマ株式会社\nアプリエンジニアのメンバーとして以下に従事- Windows7向け対話形式3D-CAD/CAM・2D-CAD/CAMアプリケーション開発の要件定義・テスト業務\nLink"
  },
  {
    "objectID": "index.html#スキルレベル",
    "href": "index.html#スキルレベル",
    "title": "職務経歴書",
    "section": "4. スキルレベル",
    "text": "4. スキルレベル\n★：業務経験あり\n\n\n\n\n\n\n\n\n\n項目\n種類\n使用期間\nレベル\n\n\n\n\nOS\nLinux (Ubuntu, WSL2 Ubuntu, Amazon Linux)\n3年★\n要件に応じた環境構築、開発環境利用が可能\n\n\n\nWindows\n9年★\n要件に応じた環境構築、開発環境利用が可能\n\n\n\nMac\n0.25年★\n要件に応じた環境構築、開発環境利用が可能\n\n\n言語\nPython\n3年★\n一人称で作業可能\n\n\n\nSQL\n2年★\n一人称で作業可能\n\n\n\nShell Script (Bash)\n3年★\n一人称で作業可能\n\n\n\nC\n3.5年★\n一人称で作業可能\n\n\nDB\nMySQL\n1年★\n調べながらであれば作業可能\n\n\n\nPostgreSQL\n1年★\n調べながらであれば作業可能\n\n\nModern Data Stack\nSnowflake\n2年★\nデータマート作成・SQLパフォーマンス改善・Snowpark ML 利用ができる\n\n\n\nBigQuery\n0.25年★\n調べながらであれば作業可能\n\n\n\ndbt\n0.5年★\n調べながらであれば作業可能\n\n\nその他\nAirflow (AWS)\n1.5年★\n要件に応じたジョブの記述ができる\n\n\n\nTerraform\n0.25年★\n調べながらであれば作業可能\n\n\n\nDocker\n2年★\nDockerfileやDocker Composeの記述・実行ができる\n\n\n\nGit / GitHub / CodeCommit\n3年★\nGit flow や GitHub flow に則った開発利用やレビューが可能\n\n\n\nGitHub Actions\n0.25年★\nTerraform 向けに fmt, validate, plan, apply 処理を記述・実行可能"
  },
  {
    "objectID": "index.html#資格",
    "href": "index.html#資格",
    "title": "職務経歴書",
    "section": "5. 資格",
    "text": "5. 資格\n\nTOEIC スコア 805 (2015年3月)\n統計検定2級 (2023年4月)"
  },
  {
    "objectID": "index.html#通常業務以外の活動",
    "href": "index.html#通常業務以外の活動",
    "title": "職務経歴書",
    "section": "6. 通常業務以外の活動",
    "text": "6. 通常業務以外の活動\n\n6.1. 自宅用ゲームサーバー構築\n\nGoogle Compute Engine (Ubuntu) にてゲームサーバーを構築しました。Cloud Functions と GAS により Slack 経由でサーバーを起動・停止できる仕組みを導入しました。\n上記サーバーを構築後、コスト節約のために自宅マシンに Ubuntu をインストールし、Docker コンテナでゲームサーバーを構築しました。systemd により S3 を用いた自動バックアップ機能や、サーバーの自動アップデート機能を実装しました。\n\nRepository: https://github.com/i9wa4/minecraft-bedrock-server-setup\n\n\n\n\n6.2. Vim 活動\n\nVim の環境構築を通して各言語の環境構築の知見を得ることができ、社内へ還元した経験があります。\nVim コミュニティのオンライン・オフラインのイベントに複数参加し Vim に関する技術情報収集や交流を行っています。\n\n参加イベント: https://connpass.com/user/19wa4/\n\nMarkdown 向けの簡易的な Formatter を Vim プラグインとして作成しました。TypeScript で作成しており Deno 環境にて動作します。\n\nRepository: https://github.com/i9wa4/markdown-number-header.vim"
  },
  {
    "objectID": "detail/02-sld.html",
    "href": "detail/02-sld.html",
    "title": "職務経歴 新光商事LSIデザインセンター株式会社",
    "section": "",
    "text": "事業内容\n\n組込ソフトウェア開発、ASIC/FPGA 開発\n\n資本金\n\n8000万円\n\n売上高\n\n16.7億円\n\n従業員数\n\n83名\n\n上場／非上場\n\n非上場\n\n雇用形態\n\n正社員\n\n勤務地\n\n北海道札幌市"
  },
  {
    "objectID": "detail/02-sld.html#会社概要雇用形態-2022年時点",
    "href": "detail/02-sld.html#会社概要雇用形態-2022年時点",
    "title": "職務経歴 新光商事LSIデザインセンター株式会社",
    "section": "",
    "text": "事業内容\n\n組込ソフトウェア開発、ASIC/FPGA 開発\n\n資本金\n\n8000万円\n\n売上高\n\n16.7億円\n\n従業員数\n\n83名\n\n上場／非上場\n\n非上場\n\n雇用形態\n\n正社員\n\n勤務地\n\n北海道札幌市"
  },
  {
    "objectID": "detail/02-sld.html#プロジェクト一覧",
    "href": "detail/02-sld.html#プロジェクト一覧",
    "title": "職務経歴 新光商事LSIデザインセンター株式会社",
    "section": "2. プロジェクト一覧",
    "text": "2. プロジェクト一覧\n新しい順に記載しております。\n\n2.1. 親会社向け車両通信プロトコル解説講義\n\n2.1.1. 期間\n\n2022年2月-3月\n\n\n\n2.1.2. 担当業務\n\n車両組込システムの通信プロトコル (CAN) の説明資料作成\n組込システムへのCAN通信実装\n上記を利用した講義実施\n\n\n\n2.1.3. 担当フェーズ\n\nなし\n\n\n\n2.1.4. 開発環境\n\nC\nアセンブラ\nRenesas CS+ V8.05.00\nRH850/C1M-A1\n\n\n\n2.1.5. 規模・役割\n\n2名\nメンバー\n\n\n\n\n2.2. 噴霧器システム開発\n\n2.2.1. 期間\n\n2021年6月-2022年1月\n\n\n\n2.2.2. 担当業務\n\nプロトタイプ向け汎用インバータ制御開発\n顧客インバータ制御開発\n噴霧器の操作器開発\n\n\n\n2.2.3. 実績・取り組み\n\n顧客要望で解析用グラフ資料作成業務が発生した際に、自主的に習得していたPythonを用いて満足いただける資料を作成できました。\n\n\n\n2.2.4. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\n\n\n\n2.2.5. 開発環境\n\nC\nアセンブラ\nRenesas CS+ V8.05.00\nRL78/G1F\nRL78/G12\n\n\n\n2.2.6. 規模・役割\n\n4名\nメンバー\n\n\n\n\n2.3. 車両緊急通報システムのマイコン移植\n\n2.3.1. 期間\n\n2020年10月-2021年5月\n\n\n\n2.3.2. 担当業務\n\nマイコン移植による故障懸念点の洗い出し\nマイコンのリソース割当検討\n各種タイマ機能とシリアル通信機能の移植\nテスト仕様書作成\nテスト実施\n\n\n\n2.3.3. 実績・取り組み\n\n5名が各々実施していた30以上のテスト仕様書のフォーマット整備をExcel VBAで自動化することで全員の負担を軽減し、特に経験の浅い1名の負担軽減に大きく貢献できました。\n\n\n\n2.3.4. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n2.3.5. 開発環境\n\nC\nアセンブラ\nGHS MULTI V2020.1.5\nQAC 7.2.3\nRH850/F1K\n\n\n\n2.3.6. 規模・役割\n\n9名\nメンバー\n\n\n\n\n2.4. 自動車トラクション制御ファームウェアの無線更新機能の開発\n\n2.4.0.1. 期間\n\n2020年4月-9月\n\n\n\n2.4.1. 担当業務\n\nバックアップ・更新処理の設計開発\nカバレッジテスト・単体テスト・結合テストの仕様書作成\nテスト実施\n\n\n\n2.4.2. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n2.4.3. 開発環境\n\nC\nアセンブラ\nGHS MULTI V2013.5.5\nQAC 8.1.1J\nwinAMS v6.3.1\nRH850/C1M\n\n\n\n2.4.4. 規模・役割\n\n8名\nメンバー\n\n\n\n\n2.5. 自動車トラクション制御開発用ファームウェアの更新機能開発\n\n2.5.1. 期間\n\n2019年10月-2020年3月\n\n\n\n2.5.2. 担当業務\n\nトラクションモータ開発基板側の通信機能・自身のROM書き換え機能の設計開発\nPCアプリ含めたシステムのテスト仕様作成\nテスト実施\n\n\n\n2.5.3. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n2.5.4. 開発環境\n\nC\nアセンブラ\nGHS MULTI V2015.1.7\nRH850/C1M-A1\n\n\n\n2.5.5. 規模・役割\n\n6名\nメンバー"
  },
  {
    "objectID": "detail/01-okuma.html",
    "href": "detail/01-okuma.html",
    "title": "職務経歴 オークマ株式会社",
    "section": "",
    "text": "事業内容\n\nCNC工作機械、CNC装置・サーボモータ・位置検出器・ソフトウェアの開発・製造、販売\n\n資本金\n\n180億円\n\n売上高\n\n1600億円\n\n従業員数\n\n3407名\n\n上場／非上場\n\n上場\n\n雇用形態\n\n正社員\n\n勤務地\n\n愛知県"
  },
  {
    "objectID": "detail/01-okuma.html#会社概要雇用形態-2018年時点",
    "href": "detail/01-okuma.html#会社概要雇用形態-2018年時点",
    "title": "職務経歴 オークマ株式会社",
    "section": "",
    "text": "事業内容\n\nCNC工作機械、CNC装置・サーボモータ・位置検出器・ソフトウェアの開発・製造、販売\n\n資本金\n\n180億円\n\n売上高\n\n1600億円\n\n従業員数\n\n3407名\n\n上場／非上場\n\n上場\n\n雇用形態\n\n正社員\n\n勤務地\n\n愛知県"
  },
  {
    "objectID": "detail/01-okuma.html#プロジェクト一覧",
    "href": "detail/01-okuma.html#プロジェクト一覧",
    "title": "職務経歴 オークマ株式会社",
    "section": "2. プロジェクト一覧",
    "text": "2. プロジェクト一覧\n新しい順に記載しております。\n\n2.1. Windows7向け対話形式3D-CAD/CAMアプリケーション開発\n\n2.1.1. 期間\n\n2017年4月-2018年7月\n\n\n\n2.1.2. 担当業務\n\n大型アップデート用UI要件定義\nテスト仕様書作成\n結合テスト・システムテスト実施\nユーザ問い合わせ対応\n不具合対応\n\n\n\n2.1.3. 担当フェーズ\n\n要件定義\nテスト\n保守\n\n\n\n2.1.4. 開発環境\n\nWindows7\nC++\n\n\n\n2.1.5. 規模・役割\n\n10名\nメンバー\n\n\n\n\n2.2. Windows7向け2D-CAD/CAMアプリケーション開発\n\n2.2.1. 期間\n\n2017年4月-2018年7月\n\n\n\n2.2.2. 担当業務\n\nテスト仕様書作成\n結合テスト・システムテスト実施\nユーザ問い合わせ対応\n受注先の工作機械に応じたチューニング\n\n\n\n2.2.3. 担当フェーズ\n\nテスト\n保守\n\n\n\n2.2.4. 開発環境\n\nWindows7\nC++\n\n\n\n2.2.5. 規模・役割\n\n5名\nメンバー"
  }
]