[
  {
    "objectID": "detail/01-okuma.html",
    "href": "detail/01-okuma.html",
    "title": "職務経歴 オークマ株式会社",
    "section": "",
    "text": "Table 1: 会社概要・雇用形態 (2018年時点)\n\n\n\n\n\n\n\n\n\n事業内容\nCNC工作機械、CNC装置・サーボモータ・位置検出器・ソフトウェアの開発・製造、販売\n\n\n資本金\n180億円\n\n\n売上高\n1600億円\n\n\n従業員数\n3407名\n\n\n上場／非上場\n上場\n\n\n雇用形態\n正社員\n\n\n勤務地\n愛知県\n以下、新しい順にプロジェクトを記載しております。"
  },
  {
    "objectID": "detail/01-okuma.html#windows7-向け対話形式-3d-cadcam-アプリケーション開発",
    "href": "detail/01-okuma.html#windows7-向け対話形式-3d-cadcam-アプリケーション開発",
    "title": "職務経歴 オークマ株式会社",
    "section": "1. Windows7 向け対話形式 3D-CAD/CAM アプリケーション開発",
    "text": "1. Windows7 向け対話形式 3D-CAD/CAM アプリケーション開発\n\n1.1. 期間\n\n2017/04 - 2018/07\n\n\n\n1.2. 担当業務\n\n大型アップデート用UI要件定義\nテスト仕様書作成\n結合テスト・システムテスト実施\nユーザ問い合わせ対応\n不具合対応\n\n\n\n1.3. 担当フェーズ\n\n要件定義\nテスト\n保守\n\n\n\n1.4. 開発環境\n\nWindows7\nC++\n\n\n\n1.5. 規模・役割\n\n10名\nメンバー"
  },
  {
    "objectID": "detail/01-okuma.html#windows7-向け-2d-cadcam-アプリケーション開発",
    "href": "detail/01-okuma.html#windows7-向け-2d-cadcam-アプリケーション開発",
    "title": "職務経歴 オークマ株式会社",
    "section": "2. Windows7 向け 2D-CAD/CAM アプリケーション開発",
    "text": "2. Windows7 向け 2D-CAD/CAM アプリケーション開発\n\n2.1. 期間\n\n2017/04 - 2018/07\n\n\n\n2.2. 担当業務\n\nテスト仕様書作成\n結合テスト・システムテスト実施\nユーザ問い合わせ対応\n受注先の工作機械に応じたチューニング\n\n\n\n2.3. 担当フェーズ\n\nテスト\n保守\n\n\n\n2.4. 開発環境\n\nWindows7\nC++\n\n\n\n2.5. 規模・役割\n\n5名\nメンバー"
  },
  {
    "objectID": "detail/02-sld.html",
    "href": "detail/02-sld.html",
    "title": "職務経歴 新光商事LSIデザインセンター株式会社",
    "section": "",
    "text": "Table 1: 会社概要・雇用形態 (2022年時点)\n\n\n\n\n\n\n\n\n\n事業内容\n組込ソフトウェア開発、ASIC/FPGA 開発\n\n\n資本金\n8000万円\n\n\n売上高\n16.7億円\n\n\n従業員数\n83名\n\n\n上場／非上場\n非上場\n\n\n雇用形態\n正社員\n\n\n勤務地\n北海道札幌市2020年3月以降は週に約3回リモートワーク実施\n以下、新しい順にプロジェクトを記載しております。"
  },
  {
    "objectID": "detail/02-sld.html#親会社向け車両通信プロトコル解説講義",
    "href": "detail/02-sld.html#親会社向け車両通信プロトコル解説講義",
    "title": "職務経歴 新光商事LSIデザインセンター株式会社",
    "section": "1. 親会社向け車両通信プロトコル解説講義",
    "text": "1. 親会社向け車両通信プロトコル解説講義\n\n1.1. 期間\n\n2022/02 - 2022/03\n\n\n\n1.2. 担当業務\n\n車両組込システムの通信プロトコル (CAN) の説明資料作成\n組込システムへのCAN通信実装\n上記を利用した講義実施\n\n\n\n1.3. 担当フェーズ\n\nなし\n\n\n\n1.4. 開発環境\n\nC\nアセンブラ\nRenesas CS+ V8.05.00\nRH850/C1M-A1\n\n\n\n1.5. 規模・役割\n\n2名\nメンバー"
  },
  {
    "objectID": "detail/02-sld.html#噴霧器システム開発",
    "href": "detail/02-sld.html#噴霧器システム開発",
    "title": "職務経歴 新光商事LSIデザインセンター株式会社",
    "section": "2. 噴霧器システム開発",
    "text": "2. 噴霧器システム開発\n\n2.1. 期間\n\n2021/06 - 2022/01\n\n\n\n2.2. 担当業務\n\nプロトタイプ向け汎用インバータ制御開発\n顧客インバータ制御開発\n噴霧器の操作器開発\n\n\n\n2.3. 実績・取り組み\n\n顧客要望で解析用グラフ資料作成業務が発生した際に、自主的に習得していたPythonを用いて満足いただける資料を作成できました。\n\n\n\n2.4. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\n\n\n\n2.5. 開発環境\n\nC\nアセンブラ\nRenesas CS+ V8.05.00\nRL78/G1F\nRL78/G12\n\n\n\n2.6. 規模・役割\n\n4名\nメンバー"
  },
  {
    "objectID": "detail/02-sld.html#車両緊急通報システムのマイコン移植",
    "href": "detail/02-sld.html#車両緊急通報システムのマイコン移植",
    "title": "職務経歴 新光商事LSIデザインセンター株式会社",
    "section": "3. 車両緊急通報システムのマイコン移植",
    "text": "3. 車両緊急通報システムのマイコン移植\n\n3.1. 期間\n\n2020/10 - 2021/05\n\n\n\n3.2. 担当業務\n\nマイコン移植による故障懸念点の洗い出し\nマイコンのリソース割当検討\n各種タイマ機能とシリアル通信機能の移植\nテスト仕様書作成\nテスト実施\n\n\n\n3.3. 実績・取り組み\n\n5名が各々実施していた30以上のテスト仕様書のフォーマット整備をExcel VBAで自動化することで全員の負担を軽減し、特に経験の浅い1名の負担軽減に大きく貢献できました。\n\n\n\n3.4. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n3.5. 開発環境\n\nC\nアセンブラ\nGHS MULTI V2020.1.5\nQAC 7.2.3\nRH850/F1K\n\n\n\n3.6. 規模・役割\n\n9名\nメンバー"
  },
  {
    "objectID": "detail/02-sld.html#自動車トラクション制御ファームウェアの無線更新機能の開発",
    "href": "detail/02-sld.html#自動車トラクション制御ファームウェアの無線更新機能の開発",
    "title": "職務経歴 新光商事LSIデザインセンター株式会社",
    "section": "4. 自動車トラクション制御ファームウェアの無線更新機能の開発",
    "text": "4. 自動車トラクション制御ファームウェアの無線更新機能の開発\n\n4.0.1. 期間\n\n2020/04 - 2020/09\n\n\n\n4.1. 担当業務\n\nバックアップ・更新処理の設計開発\nカバレッジテスト・単体テスト・結合テストの仕様書作成\nテスト実施\n\n\n\n4.2. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n4.3. 開発環境\n\nC\nアセンブラ\nGHS MULTI V2013.5.5\nQAC 8.1.1J\nwinAMS v6.3.1\nRH850/C1M\n\n\n\n4.4. 規模・役割\n\n8名\nメンバー"
  },
  {
    "objectID": "detail/02-sld.html#自動車トラクション制御開発用ファームウェアの更新機能開発",
    "href": "detail/02-sld.html#自動車トラクション制御開発用ファームウェアの更新機能開発",
    "title": "職務経歴 新光商事LSIデザインセンター株式会社",
    "section": "5. 自動車トラクション制御開発用ファームウェアの更新機能開発",
    "text": "5. 自動車トラクション制御開発用ファームウェアの更新機能開発\n\n5.1. 期間\n\n2019/10 - 2020/03\n\n\n\n5.2. 担当業務\n\nトラクションモータ開発基板側の通信機能・自身のROM書き換え機能の設計開発\nPCアプリ含めたシステムのテスト仕様作成\nテスト実施\n\n\n\n5.3. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n5.4. 開発環境\n\nC\nアセンブラ\nGHS MULTI V2015.1.7\nRH850/C1M-A1\n\n\n\n5.5. 規模・役割\n\n6名\nメンバー"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "職務経歴書",
    "section": "",
    "text": "職務経歴書 公開先\nhttps://i9wa4.github.io/resume\n\n\n\n\n\n\n\nGitHub\nhttps://github.com/i9wa4"
  },
  {
    "objectID": "index.html#職務要約",
    "href": "index.html#職務要約",
    "title": "職務経歴書",
    "section": "1. 職務要約",
    "text": "1. 職務要約\n北海道大学卒業後、Windowsアプリエンジニアや組込エンジニアとして6年勤務しました。\nその後株式会社シイエヌエス北海道にてデータエンジニアとして2年間データパイプライン構築や機械学習ワークフロー構築業務に従事し、サブリーダーやリーダーを任されてきました。\n2024年4月から現職である株式会社hacomonoにて一人データエンジニアとしてデータ基盤の構築・運用・保守業務に従事しております。札幌にてフルリモートの勤務となります。"
  },
  {
    "objectID": "index.html#活かせる経験知識技術",
    "href": "index.html#活かせる経験知識技術",
    "title": "職務経歴書",
    "section": "2. 活かせる経験・知識・技術",
    "text": "2. 活かせる経験・知識・技術\n役割面では前職シイエヌエス北海道にてプロジェクトのリーダーやサブリーダーを任されておりました。現職 hacomono ではメンバー採用ではあるものの、入社直後にデータエンジニアが私1名のみになった都合でデータ基盤関連のタスク管理・社内調整・目標管理といったリーダー相当の業務を担当しております。\n技術面では Snowflake データマート整備、Airflow & dbt のデータパイプライン構築運用保守、Embulk による BigQuery へのデータ転送の運用保守、Terraform によるデータ基盤の IaC 化の推進、機械学習ワークフロー構築運用保守などの知見があります。"
  },
  {
    "objectID": "index.html#スキルレベル",
    "href": "index.html#スキルレベル",
    "title": "職務経歴書",
    "section": "3. スキルレベル",
    "text": "3. スキルレベル\n★：業務経験あり\n\n\n\n\n\n\n\n\n\n項目\n種類\n使用期間\nレベル\n\n\n\n\nOS\nAmazon Linux / Ubuntu\n★3年\n要件に応じた環境構築や開発環境利用が可能\n\n\n言語\nPython\n★3年\n一人称で作業可能\n\n\n言語\nSQL\n★2年\n一人称で作業可能\n\n\n言語\nShell Script\n★3年\n一人称で作業可能\n\n\nDB\nMySQL / PostgreSQL\n★1年\n不具合調査等でのデータ閲覧可能\n\n\nCloud\nAWS\n★2年\nEC2 / ECS / StepFunctions / SageMaker / Cloud9 / Airflow (MWAA) 等を含む環境構築や作業が可能\n\n\nCloud\nGoogle Cloud\n★0.5年\nCompute Engine / Cloud Functions / Datastream / BigQuery (後述) 等を含む環境構築や作業が可能\n\n\nCloud (Data)\nSnowflake\n★2年\nデータマート作成 / SQL パフォーマンス改善 / Snowpark ML 利用 / パラメータ管理が可能\n\n\nCloud (Data)\nBigQuery\n★0.3年\nBigQuery 関連の権限管理やデータセット・テーブル作成を Terraform 管理に移行することが可能\n\n\nCloud (ML)\nDataRobot\n★2年\nオートパイロットや blueprint 固定でのモデルデプロイ・運用、各種評価指標の取得の実装が可能\n\n\nIaC\nDocker\n★2年\nDockerfile や Docker Compose の記述・実行が可能\n\n\nIaC\nTerraform\n★0.3年\nBigQuery 関連の IaC 化作業が可能\n\n\nその他\nGit / GitHub / CodeCommit\n★3年\nGit flow や GitHub flow に則った開発利用やレビューが可能\n\n\nその他\nGitHub Actions\n★0.5年\n既存ワークフロー改修 / GitHub Pages 関連のワークフロー作成が可能\n\n\nその他 (Data)\ndbt Core\n★0.5年\nスクラッチから marts まで書きあげることが可能\n\n\nその他 (Data)\nEmbulk\n★0.3年\n転送元 DB や 利用するインスタンス性能に応じたパフォーマンス改善が可能"
  },
  {
    "objectID": "index.html#職務経歴",
    "href": "index.html#職務経歴",
    "title": "職務経歴書",
    "section": "4. 職務経歴",
    "text": "4. 職務経歴\n新しい順に記載しております。\n\n\n\n\n\n\n\n\n\n在籍期間\n所属\n概要\n詳細\n\n\n\n\n2024/04 - 現在\n株式会社hacomonoプロダクト 基盤本部 データ基盤部\nデータエンジニアのメンバーとして以下に従事- 自社環境・顧客環境の DWH 構築・運用- 自社データ基盤の運用改善・機能追加\n詳細\n\n\n2022/04 - 2024/03\n株式会社シイエヌエス北海道デジタルビジネス推進部\nデータエンジニアのサブリーダーやリーダーとして以下に従事- データパイプライン構築- 機械学習ワークフロー構築\n詳細\n\n\n2018/08 - 2022/03\n新光商事LSIデザインセンター株式会社ソフト開発一部 開発二課\n組込エンジニアのメンバーとして以下に従事- 車載マイコンの機能開発- インバータやモータの制御開発\n詳細\n\n\n2016/04 - 2018/07\nオークマ株式会社FAシステム本部 FA開発部 ITプラザ開発課\nアプリエンジニアのメンバーとして以下に従事- Windows 用 CAD/CAM アプリ開発の要件定義・テスト\n詳細\n\n\n\n\n4.1. 最も苦労したプロジェクト\n前職で2023年12月～2024年3月にリーダーとして参画していた以下です。AI プラットフォームのリプレイスのためにワークフロー全体の技術選定から設計まで行いました。\n情報通信企業向け 機械学習ワークフローと AI プラットフォーム移管 | 職務経歴 株式会社シイエヌエス北海道"
  },
  {
    "objectID": "index.html#資格",
    "href": "index.html#資格",
    "title": "職務経歴書",
    "section": "5. 資格",
    "text": "5. 資格\n\n\n\n[2012/11] 普通自動車第一種運転免許\n[2015/03] TOEIC スコア 805\n\n\n\n[2023/04] 統計検定2級"
  },
  {
    "objectID": "index.html#興味関心",
    "href": "index.html#興味関心",
    "title": "職務経歴書",
    "section": "6. 興味・関心",
    "text": "6. 興味・関心\n\n\n\n6.1. 興味・関心 (技術面)\n\nSnowflake / BigQuery / dbt の知見を深める\nデータガバナンスに関する経験を積む\nLLM の下支え (ベクトルデータベース構築など)\nMLOps の実践\n\n\n\n\n6.2. 興味・関心 (役割面)\n\n[直近] データエンジニアとしてリーダー経験・マネジメント経験を積む\n[3-5年後] データ関連業務の PjM や PdM (あるいは EM) として会社の売上に貢献できる立場になる"
  },
  {
    "objectID": "index.html#通常業務以外の活動",
    "href": "index.html#通常業務以外の活動",
    "title": "職務経歴書",
    "section": "7. 通常業務以外の活動",
    "text": "7. 通常業務以外の活動\n\n7.1. 社外へのアウトプット\n\n[2024/07/02] hacomonoデータ基盤におけるデータ転送の課題と今後の対応 - hacomono TECH BLOG\n[2024/08予定] Findy Tools への BigQuery・Terraform のレビュー寄稿\n\n\n\n7.2. 自宅用ゲームサーバー構築\n\nGCE (Ubuntu) / Cloud Functions / GAS により Slack 経由で起動・停止できるゲームサーバーを構築しました。\n自宅 Ubuntu マシンにも Docker でゲームサーバーを構築し systemd によるサーバーの自動アップデート機能と AWS S3 への自動バックアップ機能を実装しました。\n\nRepository: https://github.com/i9wa4/minecraft-bedrock-server-setup\n\n\n\n\n7.3. Vim 活動\n\nVim コミュニティのイベントに複数参加し Vim に関する技術情報収集や交流を行っています。\nMarkdown 向け Formatter を Vim プラグインとして TypeScript (Deno) で作成しました。\n\nRepository: https://github.com/i9wa4/vim-markdown-number-header"
  },
  {
    "objectID": "detail/04-hacomono.html",
    "href": "detail/04-hacomono.html",
    "title": "職務経歴 株式会社hacomono",
    "section": "",
    "text": "Table 1: 会社概要・雇用形態 (2024年時点)\n\n\n\n\n\n\n\n\n\n事業内容\n月額型店舗のための会員管理・予約・キャッシュレス決済システム「hacomono」開発・販売\n\n\n資本金\n100百万円\n\n\n売上高\n非公開\n\n\n従業員数\n217名\n\n\n上場／非上場\n非上場\n\n\n雇用形態\n正社員\n\n\n勤務地\nフルリモート (居住地 北海道札幌市)年に数回東京原宿本社へ出社\n以下、新しい順にプロジェクトを記載しております。"
  },
  {
    "objectID": "detail/04-hacomono.html#プロジェクト以外の社内業務",
    "href": "detail/04-hacomono.html#プロジェクト以外の社内業務",
    "title": "職務経歴 株式会社hacomono",
    "section": "1. プロジェクト以外の社内業務",
    "text": "1. プロジェクト以外の社内業務\n\n1.1. 会社テックブログ執筆\n\n[2024/07/02] hacomonoデータ基盤におけるデータ転送の課題と今後の対応 - hacomono TECH BLOG"
  },
  {
    "objectID": "detail/04-hacomono.html#顧客環境-bigquery-へのリアルタイム転送システム開発運用",
    "href": "detail/04-hacomono.html#顧客環境-bigquery-へのリアルタイム転送システム開発運用",
    "title": "職務経歴 株式会社hacomono",
    "section": "2. 顧客環境 BigQuery へのリアルタイム転送システム開発・運用",
    "text": "2. 顧客環境 BigQuery へのリアルタイム転送システム開発・運用\n\n2.1. 概要\n\nhacomono に蓄積されたデータを顧客環境 BigQuery へリアルタイム転送するためのシステム開発・運用\n\n\n\n2.2. 期間\n\n2024/04 - 現在\n\n\n\n2.3. 規模・役割\n\n[2024/04 - 2024/05]\n\n役割：メンバー\n規模：2名\n\n[2024/06 - 現在]\n\n役割：リーダー\n規模：1名\n\n\n\n\n2.4. 担当業務\n\n[2024/04 - 2024/05] (2名) 開発引き継ぎ\n[2024/06 - 現在] (私1名) 開発・運用\n\n\n\n2.5. 機能開発・実装詳細\n\n\nGitHub と Terraform (Terragrunt) を用いて以下の構成を実装します。\n\n[主機能] RDS MySQL のデータを Datastream によってリアルタイムに転送させる\n\n(新規実装) [周辺機能] ログ出力\n\n\n\n\n\n2.6. 目的・背景\n\n顧客要望がありリアルタイム性を重視したテーブルに絞って機能を提供することとなりました。\n個社向け開発として進めていますが他社への展開も可能な状態に整備する必要があります。\n\n\n\n2.7. 課題\n\n前任者から引き継いだ状態のリポジトリが雑然としており各社向けの設定ファイルを切り替えることができず大規模なリファクタリングが必要でした。\nDatastream の知見のある方が社内にいないため障害発生時の対応のノウハウがない状態でした。\n\n\n\n2.8. 工夫した点\n\n\n現在工夫中です。\n\n\n\n2.9. 成果\n\n\nDatastream の知見のある方が社内にいないため障害発生時の対応のノウハウがない状態でした。\n\n\nRDS 再起動による接続断から復旧する必要がありストリームの復元を行うことがありましたが、この経験により障害発生時に欠損し得るデータに関して説明ができるようになりました。\n本機能のオプションサービス化にあたり懸念事項の解像度を上げ、サービスのマニュアル更新の準備に役立てることができました。\ncf. ストリームを復元する | Datastream | Google Cloud\n\n\n2.10. 担当フェーズ\n\n詳細設計\n開発\nテスト\n運用\n保守\n\n\n\n2.11. 開発環境\n\nGitHub\nTerraform\nTerragrunt\nAWS\n\nRDS MySQL\nVPC\n\nGoogle Cloud\n\nBigQuery\nDatastream"
  },
  {
    "objectID": "detail/04-hacomono.html#顧客環境-bigquery-へのバッチ転送システム開発運用",
    "href": "detail/04-hacomono.html#顧客環境-bigquery-へのバッチ転送システム開発運用",
    "title": "職務経歴 株式会社hacomono",
    "section": "3. 顧客環境 BigQuery へのバッチ転送システム開発・運用",
    "text": "3. 顧客環境 BigQuery へのバッチ転送システム開発・運用\n\n3.1. 概要\n\nhacomono に蓄積されたデータを顧客環境 BigQuery へ日次バッチ転送するためのシステム開発・運用\n\n\n\n3.2. 期間\n\n2024/04 - 現在\n\n\n\n3.3. 規模・役割\n\n[2024/04 - 2024/05]\n\n役割：メンバー\n規模：2名\n\n[2024/06 - 現在]\n\n役割：リーダー\n規模：1名\n\n\n\n\n3.4. 担当業務\n\n[2024/04 - 2024/05] (2名) 定常運用業務・業務引き継ぎ\n[2024/06 - 現在] (私1名) 定常運用業務・障害対応\n\n\n\n3.5. 機能開発・実装詳細\n\nGitHub と Terraform (Terragrunt) を用いて以下の構成を実装します。\n\nRDS MySQL or Aurora MySQL をデータソースとして Embulk で顧客環境 BigQuery にデータ転送を行う\n\nシステム構成図は下記ブログをご参照ください。\n\nhacomonoデータ基盤におけるデータ転送の課題と今後の対応 - hacomono TECH BLOG\n\n\n\n\n3.6. 目的・背景\n\n顧客に向けて DWH 提供を行うサービスを開始するために暫定的に構築したシステムを運用し続けている状況です。\n\n\n\n3.7. 課題\n\n全量のデータを転送させているためデータ増加により転送時間が延びてしまい、具体的には以下の問題が起こるようになりました。\n\nRDS BurstBalance を使い切ることによる転送の不安定化が起こる\nデータソース側の DB で一時領域不足になる\n顧客約束の時刻に転送が間に合わなくなる\n\n\n\n\n3.8. 工夫した点\n\n問題発生源の特定のために Embulk のログやデータソースのメトリクスから真因を究明するよう努めました。\n\n\n\n3.9. 成果\n\n\n\nRDS BurstBalance を使い切ることによる転送の不安定化が起こる\n\n\nReadIOPS の数値が支配的だったため並列実行数を減らしたり、Embulk の読み込み量のパラメータを調整したりすることで BurstBalance を使い切らないまま可能な限り早く転送させるよう調整を行いました。\n\n\n3.10. 担当フェーズ\n\n運用\n保守\n\n\n\n3.11. 開発環境\n\nGitHub\nTerraform\nEmbulk\nAWS\n\nECS\nRDS MySQL\nAurora MySQL\nVPC\n\nGoogle Cloud\n\nBigQuery"
  },
  {
    "objectID": "detail/04-hacomono.html#社内-bigquery-環境構築運用",
    "href": "detail/04-hacomono.html#社内-bigquery-環境構築運用",
    "title": "職務経歴 株式会社hacomono",
    "section": "4. 社内 BigQuery 環境構築・運用",
    "text": "4. 社内 BigQuery 環境構築・運用\n\n4.1. 概要\n\nhacomono プロダクトのデータベースから BigQuery へデータを転送し社内向けに DWH を作成するシステムの運用・保守\n\n\n\n4.2. 期間\n\n2024/04 - 現在\n\n\n\n4.3. 規模・役割\n\n[2024/04 - 2024/05]\n\n役割：メンバー\n規模：2名\n\n[2024/06 - 現在]\n\n役割：リーダー\n規模：1名\n\n\n\n\n4.4. 担当業務\n\n[2024/04 - 2024/05] (2名) 定常運用業務・業務引き継ぎ\n[2024/06 - 現在] (私1名) 定常運用業務・運用改善業務\n\n\n\n4.5. 機能開発・実装詳細\n\n(新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能\n\n\n\n4.6. 目的・背景\n\n社内の分析需要に応えるために権限管理の行き届いた新しい BigQuery 環境を構築・運用が必要となりました。\n\n\n\n4.7. 課題\n\n\n(新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能\n\n\n概ね IaC 対応が済んでいましたが権限追加に関してはコンソールからの手動追加対応となっておりました。これにより環境差分が生じ terraform apply が通らなくなる状況でした。\n\n\n4.8. 工夫した点\n\n\n(新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能\n\n\n権限を最小限に留めるためにプロジェクトレベルでの権限付与をせず、データセット毎に権限を付与する運用に変更しました。\n\n\n4.9. 成果\n\n\n(新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能\n\n\nIaC 化により権限の種類とユーザーを CSV ファイルに集約でき、権限付与状況をリポジトリで管理できるようになりました。\n\n\n4.10. 担当フェーズ\n\n運用\n保守\n\n\n\n4.11. 開発環境\n\nGitHub\nTerraform\nEmbulk\nAWS\n\nECS\nRDS MySQL\nAurora MySQL\nVPC\n\nGoogle Cloud\n\nBigQuery"
  },
  {
    "objectID": "detail/03-cnsh.html",
    "href": "detail/03-cnsh.html",
    "title": "職務経歴 株式会社シイエヌエス北海道",
    "section": "",
    "text": "Table 1: 会社概要・雇用形態 (2024年時点)\n\n\n\n\n\n\n\n\n\n事業内容\nアプリケーション開発・インフラ構築事業、クラウド構築事業、データ分析・AI事業、DX支援事業\n\n\n資本金\n2500万円\n\n\n売上高\n7億5,351万円\n\n\n従業員数\n39名\n\n\n上場／非上場\n非上場\n\n\n雇用形態\n正社員\n\n\n勤務地\n北海道札幌市週に約4回リモートワーク実施\n以下、新しい順にプロジェクトを記載しております。"
  },
  {
    "objectID": "detail/03-cnsh.html#プロジェクト以外の社内業務",
    "href": "detail/03-cnsh.html#プロジェクト以外の社内業務",
    "title": "職務経歴 株式会社シイエヌエス北海道",
    "section": "1. プロジェクト以外の社内業務",
    "text": "1. プロジェクト以外の社内業務\n\n1.1. 新卒採用一次選考の面接官対応\n\n2024年新卒採用：学生6名分\n2025年新卒採用：学生6名分\n\n\n\n1.2. データ分析業務担当者育成\n\n育成用プログラム進捗管理 (2023/06 - 2023/12)\n\n利用教材：データサイエンス100本ノック\n育成対象者：7名 (2023年度)\n業務：環境構築手順作成・質疑応答対応・作業進捗管理 (すべて私1名で対応)\n\nローカル上の環境構築手順の共有 (随時)\n\n社内 Wiki にて記事作成\n具体例\n\nAmazon Linux (EC2) + Anaconda + PyStan 環境構築\nWindows + Anaconda + PyStan 環境構築\nUbuntu (WSL2) + Docker (Dockerfile) + CPython + venv 環境構築\nUbuntu (WSL2) + Docker 環境構築 (データサイエンス100本ノック向け)\nAmazon Linux (Cloud9) + pyenv 環境構築\nVSCode と Vim での Linter Formatter 導入方法\n\n\nデータ分析関連技術情報共有 (随時)\n\nニュースサイト・技術ブログ・技術コミュニティにて情報収集し、社内チャットにて随時共有"
  },
  {
    "objectID": "detail/03-cnsh.html#情報通信企業向け-機械学習ワークフローと-ai-プラットフォーム移管",
    "href": "detail/03-cnsh.html#情報通信企業向け-機械学習ワークフローと-ai-プラットフォーム移管",
    "title": "職務経歴 株式会社シイエヌエス北海道",
    "section": "2. 情報通信企業向け 機械学習ワークフローと AI プラットフォーム移管",
    "text": "2. 情報通信企業向け 機械学習ワークフローと AI プラットフォーム移管\n\n2.1. 概要\n\nDataRobot 中心で構築していた機械学習ワークフローから Snowpark ML (Snowflake) 中心の構築への移管\n\n\n\n2.2. 期間\n\n[2023/12 - 2024/01] Snowpark ML 事前検証\n[2024/02 - 2024/03] 追加調査・ワークフロー設計\n\n\n\n2.3. 規模・役割\n\n[2023/12 - 2024/01]\n\n役割：メンバー\n規模：1名 (私)\n\n[2024/02 - 2024/03]\n\n役割：リーダー\n規模：2名\n\n自社の若手2名\n\n\n\n\n\n2.4. 担当業務\n\n[2023/12 - 2024/01] (私1名) Snowpark ML の事前検証\n[2024/02 - 2024/03] (2名) DataRobot から Snowpark ML への移管のための追加調査\n[2024/03] (私1名) ワークフロー設計\n\n\n\n2.5. 機能開発・実装詳細\n移管前後の構築詳細は以下の通りです。\n\n移管前構築 (AWS MWAA + ECS + DataRobot + Snowflake)\n\nMWAA にてワークフロー管理を行っており DAG ファイルにてジョブを定義し並列処理や直列処理を記述していました。\nMWAA KubernetesPodOperator にて利用する ECS イメージを JupyterHub (ノートブック実行環境) でも共有していたため本番と開発でライブラリ依存関係の齟齬がない環境でした。\nAI プラットフォームとして DataRobot を採用し、ハイパーパラメータチューニングやモデル評価を全てフルマネージドで実施させていました。ただしコストが嵩む問題がありました。\n\n移管後構築 (AWS SageMaker + Snowpark ML + Snowflake)\n\nAI プラットフォームとして Snowpark ML を採用することとしました。使用感は scikit-learn に近く、ラベルエンコーディング・ハイパーパラメータチューニング・モデル評価を自力で実装する必要があります。\nワークフローは “SageMaker + Papermill” でノートブック上での管理となります。\nモデルはモデルレジストリ機能にて管理させます。\n他部署 (他の環境) とも共有できるように素朴な実装を目指しました。\n\n\n\n\n2.6. 目的・背景\n\nコスト上の問題から DataRobot の利用を2024年8月に停止するという判断を受けて AI プラットフォームの移行先を探す必要がありました。\n\n\n\n2.7. 課題\n\n移行業務は付加価値を生みづらい都合で移行先調査の優先順位が低くなってしまい、分析基盤管理側の社員も移行先調査がほとんど実施できていない状況でした。\nSnowpark ML は新しいサービスのため公式ドキュメント以外で参照出来る情報が社内外ともにかなり限られている状況でした。\n\n\n\n2.8. 工夫した点\n\n調査作業での工夫点\n\n後から続く方が参照しやすいように調査記録を丁寧に取りました。\n\nSnowflake 公式のリポジトリに置かれているサンプルコードや公式ドキュメント・公式ライブラリソースコードのどの部分を参照したか記録に残しました。\n調査記録を客先社内公開済み。\n\n必要最低限の領域までの調査に留めることで、スケジュールや実装方針について予定より早く合意を取ることができました。\n\n関係者が多くなるため情報提供をいち早く行うことを優先しました。\n\n\n\n\n\n2.9. 成果\n\nSnowpark ML の利用は前例が少なかったため Snowflake 社からの個別開示情報などを利用して情報収集と事前検証を行ないました。結果、既存ワークフローに比べてコスト・性能面・セキュリティ面で優位性があることを示し、客先での先行事例を作ることができました。\n\n価値を生みづらいと見込まれていた移管作業の意義を示したため、注目度を上げ、周囲を巻き込むことに成功しました。客先での社内政治的にも Snowpark ML 導入推進の話を通しやすくなる状況作りに貢献しました。\n\n本プロジェクトではリーダーとして技術調査・スケジュール策定・チームへの作業指示・顧客他部署への情報共有など多様な役割を担うことができました。\n\n\n\n2.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n2.11. 開発環境\n\nAWS\n\nSageMaker\nCodeCommit\nSecrets Manager\n\nSQL\n\nSnowflake\n\nPython 実行環境\n\nSageMaker (conda_python3)\n\nAI プラットフォーム\n\nSnowpark ML"
  },
  {
    "objectID": "detail/03-cnsh.html#情報通信企業向け-データマート整備",
    "href": "detail/03-cnsh.html#情報通信企業向け-データマート整備",
    "title": "職務経歴 株式会社シイエヌエス北海道",
    "section": "3. 情報通信企業向け データマート整備",
    "text": "3. 情報通信企業向け データマート整備\n\n3.1. 概要\n顧客情報と紐付けて分析や機械学習に利用するための下記特徴量の作成\n\nポイントサービス加盟店と顧客推定住所との距離\nポイントサービス詳細情報\n決済情報\n様々な特徴量を次元圧縮して生成する特徴量\n行動履歴からルールベースで推定されたライブイベント実績\n\n\n\n3.2. 期間\n\n[2023/04 - 2023/05] ポイントサービス加盟店と顧客推定住所との距離\n[2023/06 - 2023/07] 決済情報\n[2023/08 - 2023/09] 行動履歴からルールベースで推定されたライフイベント実績\n[2023/10 - 2023/12] 様々な特徴量を次元圧縮して生成する特徴量\n[2024/01 - 2024/03] ポイントサービス詳細情報\n\n\n\n3.3. 規模・役割\n\n役割：サブリーダー\n規模：4名\n\n\n\n3.4. 担当業務\n\n(主に私1名) データ作成月次作業向けワークフロー構築\n(4名) データレイク調査\n(4名) データ抽出クエリ作成\n(リーダーと私の2名) レビュー\n(4名) 検証\n(4名) 保守\n(4名) 月次運用作業\n\n\n\n3.5. 機能開発・実装詳細\nデータマート構成のためのクエリは Juupyter Notebook 上から Python API 経由で実行していましたが、2023年秋頃から dbt Core を導入し SQL ファイルベースへ置き替えつつある状況でした。\n\n[旧環境] Snowflake の Python API 利用 (Jupyter Notebook にて管理)\n\nSnowflake Python API を Jupyter Notebook から実行します。\n\nファイル数が増えたりコード量が増えるとコードの見通しが悪くなりやすい欠点があります。\n\nワークフローは MWAA にて構築しています。\n\n[新環境] dbt Core 利用 (SQL ファイルベース)\n\ndbt Core により SQL ファイル主体で管理を行います。\n\n入出力の依存関係が明示され管理が容易になります。\nCI/CD、自動テスト、自動ドキュメント生成など現代的な開発・運用が可能となります。\n必要に応じて増分データのみを対象とするクエリに変更できます。\n\n\n\n\n\n3.6. 目的・背景\n\nデータレイクは充実しているものの、機械学習や顧客情報分析に利用できるデータマートは発展途上のため適宜追加していく必要がありました。\n\n\n\n3.7. 課題\n\n分析に利用できる特徴量が不足している状況でした。\n従来作成していた特徴量が上流データの仕様変更や不具合によって作ることができない場合がありました。\nJupyter Notebook で管理しているデータマート向けプログラムが長大なため不具合発生時の原因究明に時間が掛かることが多くありました。\n上流データが全て揃ったタイミングでデータマートの月次更新を行っておりましたが、一部情報をできるだけ早く更新してほしいと言われるようになりました。\n\n\n\n3.8. 工夫した点\n\n\n分析に利用できる特徴量が不足している状況でした。\n従来作成していた特徴量が上流データの仕様変更や不具合によって作ることができない場合がありました。\n\n\n\nユーザーアンケートにより整備すべきデータを決定し、より必要とされるデータマートを目指しました。\nできるだけ早くデータを提供できるような上流データを選定しつつ、上流データの障害発生率を調査し取捨選択を行いました。信頼性の高いデータマート運用のために設計時に十分考慮を行いました。\n\n\n\nJupyter Notebook で管理しているデータマート向けプログラムが長大なため不具合発生時の原因究明に時間が掛かることが多くありました。\n上流データが全て揃ったタイミングでデータマートの月次更新を行っておりましたが、一部情報をできるだけ早く更新してほしいと言われるようになりました。\n\n\n\nいずれも解消できるポテンシャルをもつ dbt に移行することとしました。\n\n\n\n3.9. 成果\n\nユーザー目線での改善を続けたことでデータマートのアクセス数増加につながり、部内の大きな成果として表彰を受けました。\n自チーム・他チームともに顧客行動予測を行っており、そのために必要な特徴量を自力で作成し社内の多様なモデルの精度向上に貢献できました。\ndbt 移行を推進することでソースコードを SELECT 文中心の理解しやすいものに置き換えることができました。\n上流データが追加されたタイミングで必要に応じてデータ作成処理を行える (セマンティックレイヤ対応ができる) ように dbt 環境に移行を順次進めることができています。\n\nセマンティックレイヤ対応は dbt Core では非対応のため dbt Cloud 導入時の対応となります。\n\n\n\n\n3.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n運用\n保守\n\n\n\n3.11. 開発環境\n\nAWS\n\nCodeCommit\nCloud9\nSecrets Manager\nSageMaker\nMWAA\nEKS\nECS\n\nSQL\n\nSnowflake\ndbt\n\nPython 実行環境\n\nSageMaker (conda_python3)\nJupyterHub (conda_python3)"
  },
  {
    "objectID": "detail/03-cnsh.html#情報通信企業向け-機械学習ワークフローのクラウドシフト",
    "href": "detail/03-cnsh.html#情報通信企業向け-機械学習ワークフローのクラウドシフト",
    "title": "職務経歴 株式会社シイエヌエス北海道",
    "section": "4. 情報通信企業向け 機械学習ワークフローのクラウドシフト",
    "text": "4. 情報通信企業向け 機械学習ワークフローのクラウドシフト\n\n4.1. 概要\n\nオンプレ基盤で実施していた顧客行動予測モデル作成 (50モデル分) ワークフローのクラウドシフト\n\n\n\n4.2. 期間\n\n[2022/07 - 2022/10] 28モデル分\n[2022/11 - 2023/03] 22モデル分\n\n\n\n4.3. 規模・役割\n\n規模：4名\n役割：メンバー\n\n\n\n4.4. 担当業務\n\n(私1名) ワークフロー設計・実装\n(私1名) 各ジョブ設計\n(4名) 各ジョブ実装\n(4名) 上流データ調査\n(4名) 機械学習用データ作成クエリの再構成\n(4名) 検証\n(4名) 保守\n\n\n\n4.5. 機能開発・実装詳細\nMWAA (Airflow) + EKS + Kubernetes + Papermill な Python 実行環境が構築済みのため以下の要領で実装を行いました。\n\nMWAA ワークフローを設計し DAG ファイルとして実装\n\n大まかにはモデル共通処理を実行した後、モデル固有の処理を並列で実行する流れです。\n\nSnowflake Python API と DataRobot API を実行する Python コード (Jupyter Notebook) を各ジョブの設計内容に応じて作成\n\n機械学習用データ作成・モデリング・スコアリング・モデル評価指標取得などの処理を実装します。\n\n\n\n\n4.6. 目的・背景\n\n従来の基盤の廃止に伴い AWS 基盤にて機械学習ワークフローを構築する必要がありました。\n\n\n\n4.7. 課題\n\n上流データは仕様が変わりつつ移行済みだったため、従来基盤で利用していたクエリと同等のものを作るには調査・検証の時間を大きく取る必要がありました。\nMWAA と DataRobot に関するノウハウがチーム内になく、自力で調査をしつつ基盤担当者から情報提供を受けながら取り組む必要がありました。\n\n\n\n4.8. 工夫した点\n\nMWAA (Airflow) + EKS + Kubernetes + Papermill の構成で並列処理に強いことを利用し、並列処理を最大限活用できるようにジョブの粒度を調整しました。\n移行対象のクエリの量が膨大かつ移行先上流データがどれか分からない状況だったため、初期調査段階では件数比較を活用しある程度当たりを付ける方法で効率的に設計を進めました。\n\n最終的にはレコードの一致率確認を行っていますが、初めから一致率確認をしていると時間が足りなかったと思われます。\n\nMWAA による機械学習ワークフロー構築時に従来手動で実施していた検証処理も含め、最終的に Slack 通知確認で完了するように作業を簡素化することで単純な移行ではなく価値を生むことを意識しました。\n\n\n\n4.9. 成果\n\n従来と同等のワークフローを維持しつつ、自動化と時短の工夫を入れることで大幅に運用工数を減らすことができました。\n\n\n\n4.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n保守\n運用\n\n\n\n4.11. 開発環境\n\nAWS\n\nSageMaker\nCodeCommit\nSecrets Manager\nMWAA\nEKS\nECS\n\nSQL\n\nSnowflake\n\nPython 実行環境\n\nSageMaker (conda_python3)\nJupyterHub (conda_python3)\n\nAI プラットフォーム\n\nDataRobot"
  },
  {
    "objectID": "detail/03-cnsh.html#小売企業向け-客数予測処理実行環境構築",
    "href": "detail/03-cnsh.html#小売企業向け-客数予測処理実行環境構築",
    "title": "職務経歴 株式会社シイエヌエス北海道",
    "section": "5. 小売企業向け 客数予測処理実行環境構築",
    "text": "5. 小売企業向け 客数予測処理実行環境構築\n\n5.1. 概要\n\nオンプレ基盤で実施していた客数予測処理の AWS 環境移行\n\n\n\n5.2. 期間\n\n2022/05 - 2022/06\n\n\n\n5.3. 規模・役割\n\n1名\nメンバー\n\n\n\n5.4. 担当業務\n\n予測処理実行環境構築 (EC2, Python)\n環境変更に伴う Python コード修正・スクリプト作成\n予測処理実行手順構築\n\n\n\n5.5. 機能開発・実装詳細\n\nEC2 に Anaconda をインストールしベイズ統計モデル作成環境を構築します。\n顧客の要求により客数予測に費せる日数が4日程度のためその範囲内で十分終了するよう処理の並列化を行います。\n\n\n\n5.6. 目的・背景\n\n(前提) PoC として1店舗毎にベイズ統計モデルで客数予測を行うプログラムが作成されており、客数予測処理は1店舗あたり4時間程度かかる状況でした。\n\nその上で4日程度で約200店舗分の客数予測を出す環境構築を求められていました。\nインスタンス性能を上げるための AWS 移行となります。\n\n\n\n\n5.7. 課題\n\n要求を満たすためには EC2 高性能インスタンスを利用する必要がありコストは最小限とする必要がありました。\n前任者の作成した並列処理に問題があり総実行時間が長くなってしまいまう。\n経験の浅い作業者に運用を直ちに引き継ぐことになっていたため、手動実行するプロセスを挟むと不具合や遅延が想定されました。\n\n\n\n5.8. 工夫した点\n\n前任者の作成していた並列処理は先にコア数に基づきジョブを分割する形式のシェルスクリプトで構成していましたが、各店舗毎にデータ量が異なるため予測処理が早めに終了して遊びの出るコアが発生してしまっていました。\n\n改善のため xargs に並列処理を管理させることで空きコアに逐次ジョブを実行させる構成に改善させ総実行時間を短縮させることができました。\n\n\n\n\n5.9. 成果\n\n当初の構成に比べて総実行時間を短縮することができ EC2 インスタンス利用時間の削減に成功しました。\n総実行時間は2日程度に抑えることができ、顧客要求を満たすことができました。\n利用可能なリソースが EC2 のみという制約の中、スクリプトを活用し極力自動化し引継ぎ後の業務負荷を軽減させました。\n\n\n\n5.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n保守\n\n\n\n5.11. 開発環境\n\nAWS\n\nEC2\n\nSQL\n\nPostgreSQL\n\nGit\nPython 実行環境\n\nPython (公式)\nAnaconda\n\nシェルスクリプト"
  }
]